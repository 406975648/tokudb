# name       : response-time-distribution.patch
# introduced : 12
# maintainer : Oleg
#
#!!! notice !!!
# Any small change to this file in the main branch
# should be done or reviewed by the maintainer!
diff -ruN a/include/mysql_com.h b/include/mysql_com.h
--- a/include/mysql_com.h	2010-11-01 08:43:53.000000000 +0000
+++ b/include/mysql_com.h	2010-11-01 08:52:40.000000000 +0000
@@ -128,10 +128,11 @@
 #define REFRESH_FAST		32768	/* Intern flag */
 
 /* RESET (remove all queries) from query cache */
-#define REFRESH_QUERY_CACHE	65536
-#define REFRESH_QUERY_CACHE_FREE 0x20000L /* pack query cache */
-#define REFRESH_DES_KEY_FILE	0x40000L
-#define REFRESH_USER_RESOURCES	0x80000L
+#define REFRESH_QUERY_CACHE	     65536
+#define REFRESH_QUERY_CACHE_FREE    0x20000L /* pack query cache */
+#define REFRESH_DES_KEY_FILE	     0x40000L
+#define REFRESH_USER_RESOURCES	     0x80000L
+#define REFRESH_QUERY_RESPONSE_TIME 0x100000L /* response time distibution */
 
 #define CLIENT_LONG_PASSWORD	1	/* new more secure passwords */
 #define CLIENT_FOUND_ROWS	2	/* Found instead of affected rows */
diff -ruN a/patch_info/response-time-distribution.info b/patch_info/response-time-distribution.info
--- a/patch_info/response-time-distribution.info	1970-01-01 00:00:00.000000000 +0000
+++ b/patch_info/response-time-distribution.info	2010-11-01 08:52:40.000000000 +0000
@@ -0,0 +1,9 @@
+File=response-time-distribution.patch
+Name=Response time distribution
+Version=1.0
+Author=Percona <info@percona.com>
+License=GPL
+Comment=
+Changelog
+2010-07-02 first version avaliable
+2010-09-15 add column 'total'
diff -ruN a/sql/Makefile.am b/sql/Makefile.am
--- a/sql/Makefile.am	2010-11-01 08:43:52.000000000 +0000
+++ b/sql/Makefile.am	2010-11-01 08:52:40.000000000 +0000
@@ -66,7 +66,7 @@
 			sql_repl.h slave.h rpl_filter.h rpl_injector.h \
 			log_event.h rpl_record.h \
 			log_event_old.h rpl_record_old.h \
-			sql_sort.h sql_cache.h set_var.h \
+			sql_sort.h sql_cache.h set_var.h query_response_time.h \
 			spatial.h gstream.h client_settings.h tzfile.h \
 			tztime.h my_decimal.h\
 			sp_head.h sp_pcontext.h sp_rcontext.h sp.h sp_cache.h \
@@ -89,7 +89,7 @@
 			sql_string.cc sql_manager.cc sql_map.cc \
 			mysqld.cc password.c hash_filo.cc hostname.cc \
 			sql_connect.cc scheduler.cc sql_parse.cc \
-			set_var.cc sql_yacc.yy \
+			set_var.cc query_response_time.cc sql_yacc.yy \
 			sql_base.cc table.cc sql_select.cc sql_insert.cc \
 			sql_profile.cc \
 			sql_prepare.cc sql_error.cc sql_locale.cc \
diff -ruN a/sql/lex.h b/sql/lex.h
--- a/sql/lex.h	2010-11-01 08:43:53.000000000 +0000
+++ b/sql/lex.h	2010-11-01 08:52:40.000000000 +0000
@@ -415,6 +415,7 @@
   { "PURGE",		SYM(PURGE)},
   { "QUARTER",          SYM(QUARTER_SYM)},
   { "QUERY",		SYM(QUERY_SYM)},
+  { "QUERY_RESPONSE_TIME", SYM(QUERY_RESPONSE_TIME_SYM)},
   { "QUICK",	        SYM(QUICK)},
   { "RANGE",            SYM(RANGE_SYM)},
   { "READ",		SYM(READ_SYM)},
diff -ruN a/sql/mysql_priv.h b/sql/mysql_priv.h
--- a/sql/mysql_priv.h	2010-11-01 08:43:57.000000000 +0000
+++ b/sql/mysql_priv.h	2010-11-01 08:52:40.000000000 +0000
@@ -2118,6 +2118,11 @@
 extern my_bool opt_query_cache_strip_comments;
 extern my_bool opt_use_global_long_query_time;
 extern my_bool opt_slow_query_log_microseconds_timestamp;
+#ifdef HAVE_RESPONSE_TIME_DISTRIBUTION
+extern ulong   opt_query_response_time_range_base;
+extern my_bool opt_enable_query_response_time_stats;
+#endif /* HAVE_RESPONSE_TIME_DISTRIBUTION */
+extern SHOW_COMP_OPTION have_response_time_distribution;
 extern my_bool sp_automatic_privileges, opt_noacl;
 extern my_bool opt_old_style_user_limits, trust_function_creators;
 extern uint opt_crash_binlog_innodb;
diff -ruN a/sql/mysqld.cc b/sql/mysqld.cc
--- a/sql/mysqld.cc	2010-11-01 08:43:57.000000000 +0000
+++ b/sql/mysqld.cc	2010-11-01 08:52:40.000000000 +0000
@@ -32,6 +32,7 @@
 
 #include "rpl_injector.h"
 
+#include "query_response_time.h"
 #ifdef HAVE_SYS_PRCTL_H
 #include <sys/prctl.h>
 #endif
@@ -534,6 +535,10 @@
 my_bool opt_query_cache_strip_comments = 0;
 my_bool opt_use_global_long_query_time= 0;
 my_bool opt_slow_query_log_microseconds_timestamp= 0;
+#ifdef HAVE_RESPONSE_TIME_DISTRIBUTION
+ulong   opt_query_response_time_range_base  = QRT_DEFAULT_BASE;
+my_bool opt_enable_query_response_time_stats= 0;
+#endif /* HAVE_RESPONSE_TIME_DISTRIBUTION */
 my_bool lower_case_file_system= 0;
 my_bool opt_large_pages= 0;
 my_bool opt_myisam_use_mmap= 0;
@@ -684,6 +689,7 @@
 MY_LOCALE *my_default_lc_time_names;
 
 SHOW_COMP_OPTION have_ssl, have_symlink, have_dlopen, have_query_cache;
+SHOW_COMP_OPTION have_response_time_distribution;
 SHOW_COMP_OPTION have_geometry, have_rtree_keys;
 SHOW_COMP_OPTION have_crypt, have_compress;
 SHOW_COMP_OPTION have_community_features;
@@ -1394,6 +1400,9 @@
   free_global_thread_stats();
   free_global_table_stats();
   free_global_index_stats();
+#ifdef HAVE_RESPONSE_TIME_DISTRIBUTION
+  query_response_time_free();
+#endif /* HAVE_RESPONSE_TIME_DISTRIBUTION */
 #ifdef HAVE_REPLICATION
   end_slave_list();
 #endif
@@ -4114,6 +4123,9 @@
 
   init_global_table_stats();
   init_global_index_stats();
+#ifdef HAVE_RESPONSE_TIME_DISTRIBUTION
+  query_response_time_init();
+#endif /* HAVE_RESPONSE_TIME_DISTRIBUTION */
 
   /* We have to initialize the storage engines before CSV logging */
   if (ha_init())
@@ -5927,6 +5939,10 @@
   OPT_USE_GLOBAL_LONG_QUERY_TIME,
   OPT_USE_GLOBAL_LOG_SLOW_CONTROL,
   OPT_SLOW_QUERY_LOG_MICROSECONDS_TIMESTAMP,
+#ifdef HAVE_RESPONSE_TIME_DISTRIBUTION
+  OPT_QRT_RANGE_BASE,
+  OPT_ENABLE_QRT_STATS,
+#endif /* HAVE_RESPONSE_TIME_DISTRIBUTION */
   OPT_IGNORE_BUILTIN_INNODB,
   OPT_BINLOG_DIRECT_NON_TRANS_UPDATE,
   OPT_DEFAULT_CHARACTER_SET_OLD,
@@ -6998,6 +7014,23 @@
    "Use microsecond time's precision in slow query log",
    (uchar**) &opt_slow_query_log_microseconds_timestamp, (uchar**) &opt_slow_query_log_microseconds_timestamp,
    0, GET_BOOL, OPT_ARG, 0, 0, 1, 0, 1, 0},
+#ifdef HAVE_RESPONSE_TIME_DISTRIBUTION
+  {"query_response_time_range_base", OPT_QRT_RANGE_BASE,
+     "Select base of log for query_response_time ranges. WARNING: variable change affect only after flush",
+   (uchar**) &opt_query_response_time_range_base, (uchar**) &opt_query_response_time_range_base,
+   0, GET_ULONG, REQUIRED_ARG, 
+   /* def_value */  QRT_DEFAULT_BASE,
+   /* min_value */  2,
+   /* max_value */  QRT_MAXIMUM_BASE, 
+   /* sub_size */   0,
+   /* block_size */ 1,
+   /* app_type */ 0
+  },
+  {"enable_query_response_time_stats", OPT_ENABLE_QRT_STATS,
+   "Enable or disable query response time statisics collecting",
+   (uchar**) &opt_enable_query_response_time_stats, (uchar**) &opt_enable_query_response_time_stats,
+   0, GET_BOOL, REQUIRED_ARG, 0, 0, 1, 0, 1, 0},
+#endif /* HAVE_RESPONSE_TIME_DISTRIBUTION */
   {"lower_case_table_names", OPT_LOWER_CASE_TABLE_NAMES,
    "If set to 1, table names are stored in lowercase on disk and table names "
    "will be case-insensitive.  Should be set to 2 if you are using a case-"
@@ -8219,6 +8252,11 @@
 #else
   have_query_cache=SHOW_OPTION_NO;
 #endif
+#ifdef HAVE_RESPONSE_TIME_DISTRIBUTION
+  have_response_time_distribution= SHOW_OPTION_YES;
+#else /* HAVE_RESPONSE_TIME_DISTRIBUTION */
+  have_response_time_distribution= SHOW_OPTION_NO;
+#endif /* HAVE_RESPONSE_TIME_DISTRIBUTION */
 #ifdef HAVE_SPATIAL
   have_geometry=SHOW_OPTION_YES;
 #else
diff -ruN a/sql/query_response_time.cc b/sql/query_response_time.cc
--- a/sql/query_response_time.cc	1970-01-01 00:00:00.000000000 +0000
+++ b/sql/query_response_time.cc	2010-11-02 15:34:52.000000000 +0000
@@ -0,0 +1,313 @@
+#include "my_global.h"
+#include "my_atomic.h"
+#ifdef HAVE_RESPONSE_TIME_DISTRIBUTION
+#include "mysql_priv.h"
+#include "mysql_com.h"
+#include "rpl_tblmap.h"
+#include "query_response_time.h"
+
+#define TIME_STRING_POSITIVE_POWER_LENGTH QRT_TIME_STRING_POSITIVE_POWER_LENGTH
+#define TIME_STRING_NEGATIVE_POWER_LENGTH 6
+#define TOTAL_STRING_POSITIVE_POWER_LENGTH QRT_TOTAL_STRING_POSITIVE_POWER_LENGTH
+#define TOTAL_STRING_NEGATIVE_POWER_LENGTH 6
+#define MINIMUM_BASE 2
+#define MAXIMUM_BASE QRT_MAXIMUM_BASE
+#define POSITIVE_POWER_FILLER QRT_POSITIVE_POWER_FILLER
+#define NEGATIVE_POWER_FILLER QRT_NEGATIVE_POWER_FILLER
+#define STRING_OVERFLOW QRT_STRING_OVERFLOW
+#define TIME_OVERFLOW   QRT_TIME_OVERFLOW
+#define DEFAULT_BASE    QRT_DEFAULT_BASE
+
+#define do_xstr(s) do_str(s)
+#define do_str(s) #s
+#define do_format(filler,width) "%" filler width "lld"
+/*
+  Format strings for snprintf. Generate from:
+  POSITIVE_POWER_FILLER and TIME_STRING_POSITIVE_POWER_LENGTH
+  NEFATIVE_POWER_FILLER and TIME_STRING_NEGATIVE_POWER_LENGTH
+*/
+#define TIME_STRING_POSITIVE_POWER_FORMAT do_format(POSITIVE_POWER_FILLER,do_xstr(TIME_STRING_POSITIVE_POWER_LENGTH))
+#define TIME_STRING_NEGATIVE_POWER_FORMAT do_format(NEGATIVE_POWER_FILLER,do_xstr(TIME_STRING_NEGATIVE_POWER_LENGTH))
+#define TIME_STRING_FORMAT		      TIME_STRING_POSITIVE_POWER_FORMAT "." TIME_STRING_NEGATIVE_POWER_FORMAT
+
+#define TOTAL_STRING_POSITIVE_POWER_FORMAT do_format(POSITIVE_POWER_FILLER,do_xstr(TOTAL_STRING_POSITIVE_POWER_LENGTH))
+#define TOTAL_STRING_NEGATIVE_POWER_FORMAT do_format(NEGATIVE_POWER_FILLER,do_xstr(TOTAL_STRING_NEGATIVE_POWER_LENGTH))
+#define TOTAL_STRING_FORMAT		      TOTAL_STRING_POSITIVE_POWER_FORMAT "." TOTAL_STRING_NEGATIVE_POWER_FORMAT
+
+#define TIME_STRING_LENGTH	QRT_TIME_STRING_LENGTH
+#define TIME_STRING_BUFFER_LENGTH	(TIME_STRING_LENGTH + 1 /* '\0' */)
+
+#define TOTAL_STRING_LENGTH	QRT_TOTAL_STRING_LENGTH
+#define TOTAL_STRING_BUFFER_LENGTH	(TOTAL_STRING_LENGTH + 1 /* '\0' */)
+
+/*
+  Calculate length of "log linear"
+  1)
+  (MINIMUM_BASE ^ result) <= (10 ^ STRING_POWER_LENGTH) < (MINIMUM_BASE ^ (result + 1))
+
+  2)
+  (MINIMUM_BASE ^ result) <= (10 ^ STRING_POWER_LENGTH)
+  and
+  (MINIMUM_BASE ^ (result + 1)) > (10 ^ STRING_POWER_LENGTH)
+
+  3)
+  result     <= LOG(MINIMUM_BASE, 10 ^ STRING_POWER_LENGTH)= STRING_POWER_LENGTH * LOG(MINIMUM_BASE,10)
+  result + 1 >  LOG(MINIMUM_BASE, 10 ^ STRING_POWER_LENGTH)= STRING_POWER_LENGTH * LOG(MINIMUM_BASE,10)
+
+  4) STRING_POWER_LENGTH * LOG(MINIMUM_BASE,10) - 1 < result <= STRING_POWER_LENGTH * LOG(MINIMUM_BASE,10)
+
+  MINIMUM_BASE= 2 always, LOG(MINIMUM_BASE,10)= 3.3219280948873626, result= (int)3.3219280948873626 * STRING_POWER_LENGTH
+
+  Last counter always use for time overflow
+*/
+#define POSITIVE_POWER_COUNT ((int)(3.32192809 * TIME_STRING_POSITIVE_POWER_LENGTH))
+#define NEGATIVE_POWER_COUNT ((int)(3.32192809 * TIME_STRING_NEGATIVE_POWER_LENGTH))
+#define OVERALL_POWER_COUNT (NEGATIVE_POWER_COUNT + 1 + POSITIVE_POWER_COUNT)
+
+#define MILLION ((unsigned long)1000 * 1000)
+
+namespace query_response_time
+{
+
+class utility
+{
+public:
+  utility() : m_base(0)
+  {
+    m_max_dec_value= MILLION;
+    for(int i= 0; TIME_STRING_POSITIVE_POWER_LENGTH > i; ++i)
+      m_max_dec_value *= 10;
+    setup(DEFAULT_BASE);
+  }
+public:
+  uint      base()            const { return m_base; }
+  uint      negative_count()  const { return m_negative_count; }
+  uint      positive_count()  const { return m_positive_count; }
+  uint      bound_count()     const { return m_bound_count; }
+  ulonglong max_dec_value()   const { return m_max_dec_value; }
+  ulonglong bound(uint index) const { return m_bound[ index ]; }
+public:
+  void setup(uint base)
+  {
+    if(base != m_base)
+    {
+      m_base= base;
+
+      const ulonglong million= 1000 * 1000;
+      ulonglong value= million;
+      m_negative_count= 0;
+      while(value > 0)
+      {
+	m_negative_count += 1;
+	value /= m_base;
+      }
+      m_negative_count -= 1;
+
+      value= million;
+      m_positive_count= 0;
+      while(value < m_max_dec_value)
+      {
+	m_positive_count += 1;
+	value *= m_base;
+      }
+      m_bound_count= m_negative_count + m_positive_count;
+
+      value= million;
+      for(uint i= 0; i < m_negative_count; ++i)
+      {
+	value /= m_base;
+	m_bound[m_negative_count - i - 1]= value;
+      }
+      value= million;
+      for(uint i= 0; i < m_positive_count;  ++i)
+      {
+	m_bound[m_negative_count + i]= value;
+	value *= m_base;
+      }
+    }
+  }
+private:
+  uint      m_base;
+  uint      m_negative_count;
+  uint      m_positive_count;
+  uint      m_bound_count;
+  ulonglong m_max_dec_value; /* for TIME_STRING_POSITIVE_POWER_LENGTH=7 is 10000000 */
+  ulonglong m_bound[OVERALL_POWER_COUNT];
+};
+
+void print_time(char* buffer, std::size_t buffer_size, std::size_t string_positive_power_length, const char* format, uint64 value)
+{
+  memset(buffer,'X',buffer_size);
+  buffer[string_positive_power_length]= '.';
+  ulonglong second=      (value / MILLION);
+  ulonglong microsecond= (value % MILLION);
+  int result_length= snprintf(buffer, buffer_size, format, second, microsecond);
+  if(result_length < 0)
+  {
+    assert(sizeof(STRING_OVERFLOW) <= buffer_size);
+    memcpy(buffer, STRING_OVERFLOW, sizeof(STRING_OVERFLOW));
+    return;
+  }
+  buffer[result_length]= 0;
+}
+
+class time_collector
+{
+public:
+  time_collector(utility& u) : m_utility(&u)
+  {
+    my_atomic_rwlock_init(&time_collector_lock);
+  }
+  ~time_collector()
+  {
+    my_atomic_rwlock_destroy(&time_collector_lock);
+  }
+  uint32 count(uint index) const
+  {
+    my_atomic_rwlock_rdlock(&time_collector_lock);
+    uint32 result= my_atomic_load32((volatile int32*)&m_count[index]);
+    my_atomic_rwlock_rdunlock(&time_collector_lock);
+    return result;
+  }
+  uint64 total(uint index) const
+  {
+    my_atomic_rwlock_rdlock(&time_collector_lock);
+    uint64 result= my_atomic_load64((volatile int64*)&m_total[index]);
+    my_atomic_rwlock_rdunlock(&time_collector_lock);
+    return result;
+  }
+public:
+  void flush()
+  {
+    my_atomic_rwlock_wrlock(&time_collector_lock);
+    memset((void*)&m_count,0,sizeof(m_count));
+    memset((void*)&m_total,0,sizeof(m_total));
+    my_atomic_rwlock_wrunlock(&time_collector_lock);
+  }
+  void collect(uint64 time)
+  {
+    bool no_collect= false;
+    DBUG_EXECUTE_IF("response_time_distribution_log_only_more_300_milliseconds", {   \
+        no_collect= time < 300 * 1000;                                  \
+      });
+    if(no_collect) return;
+    int i= 0;
+    for(int count= m_utility->bound_count(); count > i; ++i)
+    {
+      if(m_utility->bound(i) > time)
+      {
+        my_atomic_rwlock_wrlock(&time_collector_lock);
+        my_atomic_add32((volatile int32*)(&m_count[i]), 1);
+        my_atomic_add64((volatile int64*)(&m_total[i]), time);
+        my_atomic_rwlock_wrunlock(&time_collector_lock);
+        break;
+      }
+    }
+  }
+private:
+  utility* m_utility;
+  /* The lock for atomic operations on m_count and m_total.  Only actually
+     used on architectures that do not have atomic implementation of atomic
+     operations. */
+  my_atomic_rwlock_t time_collector_lock;
+  volatile uint32   m_count[OVERALL_POWER_COUNT + 1];
+  volatile uint64   m_total[OVERALL_POWER_COUNT + 1];
+};
+
+class collector
+{
+public:
+  collector() : m_time(m_utility)
+  {
+    m_utility.setup(DEFAULT_BASE);
+    m_time.flush();
+  }
+public:
+  void flush()
+  {
+    m_utility.setup(opt_query_response_time_range_base);
+    m_time.flush();
+  }
+  int fill(THD* thd, TABLE_LIST *tables, COND *cond)
+  {
+    DBUG_ENTER("fill_schema_query_response_time");
+    TABLE        *table= static_cast<TABLE*>(tables->table);
+    Field        **fields= table->field;
+    for(uint i= 0, count= bound_count() + 1 /* with overflow */; count > i; ++i)
+    {
+      char time[TIME_STRING_BUFFER_LENGTH];
+      char total[TOTAL_STRING_BUFFER_LENGTH];
+      if(i == bound_count())
+      {        
+        assert(sizeof(TIME_OVERFLOW) <= TIME_STRING_BUFFER_LENGTH);
+        assert(sizeof(TIME_OVERFLOW) <= TOTAL_STRING_BUFFER_LENGTH);
+        memcpy(time,TIME_OVERFLOW,sizeof(TIME_OVERFLOW));
+        memcpy(total,TIME_OVERFLOW,sizeof(TIME_OVERFLOW));
+      }
+      else
+      {
+        print_time(time,sizeof(time),TIME_STRING_POSITIVE_POWER_LENGTH,TIME_STRING_FORMAT,this->bound(i));
+        print_time(total,sizeof(total),TOTAL_STRING_POSITIVE_POWER_LENGTH,TOTAL_STRING_FORMAT,this->total(i));
+      }
+      fields[0]->store(time,strlen(time),system_charset_info);
+      fields[1]->store(this->count(i));
+      fields[2]->store(total,strlen(total),system_charset_info);
+      if (schema_table_store_record(thd, table))
+      {
+	DBUG_RETURN(1);
+      }
+    }
+    DBUG_RETURN(0);
+  }
+  void collect(ulonglong time)
+  {
+    m_time.collect(time);
+  }
+  uint bound_count() const
+  {
+    return m_utility.bound_count();
+  }
+  ulonglong bound(uint index)
+  {
+    return m_utility.bound(index);
+  }
+  ulonglong count(uint index)
+  {
+    return m_time.count(index);
+  }
+  ulonglong total(uint index)
+  {
+    return m_time.total(index);
+  }
+private:
+  utility          m_utility;
+  time_collector   m_time;
+};
+
+static collector g_collector;
+
+} // namespace query_response_time
+
+void query_response_time_init()
+{
+}
+
+void query_response_time_free()
+{
+  query_response_time::g_collector.flush();
+}
+
+void query_response_time_flush()
+{
+  query_response_time::g_collector.flush();
+}
+void query_response_time_collect(ulonglong query_time)
+{
+  query_response_time::g_collector.collect(query_time);
+}
+
+int query_response_time_fill(THD* thd, TABLE_LIST *tables, COND *cond)
+{
+  return query_response_time::g_collector.fill(thd,tables,cond);
+}
+#endif /* HAVE_RESPONSE_TIME_DISTRIBUTION */
diff -ruN a/sql/query_response_time.h b/sql/query_response_time.h
--- a/sql/query_response_time.h	1970-01-01 00:00:00.000000000 +0000
+++ b/sql/query_response_time.h	2010-11-01 08:52:40.000000000 +0000
@@ -0,0 +1,71 @@
+#ifndef QUERY_RESPONSE_TIME_H
+#define QUERY_RESPONSE_TIME_H
+
+/*
+  Settings for query response time
+*/
+
+/*
+  Maximum string length for (10 ^ (-1 * QRT_STRING_NEGATIVE_POWER_LENGTH)) in text representation.
+  Example: for 6 is 0.000001
+  Always 2
+
+  Maximum string length for (10 ^ (QRT_STRING_POSITIVE_POWER_LENGTH + 1) - 1) in text representation.
+  Example: for 7 is 9999999.0
+*/
+#define QRT_TIME_STRING_POSITIVE_POWER_LENGTH 7
+#define QRT_TOTAL_STRING_POSITIVE_POWER_LENGTH 7
+
+/*
+  Minimum base for log - ALWAYS 2
+  Maximum base for log:
+*/
+#define QRT_MAXIMUM_BASE 1000
+
+/*
+  Filler for whole number (positive power)
+  Example: for
+  QRT_POSITIVE_POWER_FILLER ' '
+  QRT_POSITIVE_POWER_LENGTH 7
+  and number 7234 result is:
+  '   7234'
+*/
+#define QRT_POSITIVE_POWER_FILLER " "
+/*
+  Filler for fractional number. Similiary to whole number
+*/
+#define QRT_NEGATIVE_POWER_FILLER "0"
+
+/*
+  Message if string overflow (string overflow - internal error, this string say about bug in QRT)
+*/
+#define QRT_STRING_OVERFLOW "TOO BIG STRING"
+
+/*
+  Message if time too big for statistic collecting (very long query)
+*/
+#define QRT_TIME_OVERFLOW "TOO LONG"
+
+#define QRT_DEFAULT_BASE 10
+
+#define QRT_TIME_STRING_LENGTH				\
+  max( (QRT_TIME_STRING_POSITIVE_POWER_LENGTH + 1 /* '.' */ + 6 /*QRT_TIME_STRING_NEGATIVE_POWER_LENGTH*/), \
+       max( (sizeof(QRT_TIME_OVERFLOW) - 1),		\
+	    (sizeof(QRT_STRING_OVERFLOW) - 1) ) )
+
+#define QRT_TOTAL_STRING_LENGTH				\
+  max( (QRT_TOTAL_STRING_POSITIVE_POWER_LENGTH + 1 /* '.' */ + 6 /*QRT_TOTAL_STRING_NEGATIVE_POWER_LENGTH*/), \
+       max( (sizeof(QRT_TIME_OVERFLOW) - 1),		\
+	    (sizeof(QRT_STRING_OVERFLOW) - 1) ) )
+
+extern ST_SCHEMA_TABLE query_response_time_table;
+
+#ifdef HAVE_RESPONSE_TIME_DISTRIBUTION
+extern void query_response_time_init   ();
+extern void query_response_time_free   ();
+extern void query_response_time_flush  ();
+extern void query_response_time_collect(ulonglong query_time);
+extern int  query_response_time_fill   (THD* thd, TABLE_LIST *tables, COND *cond);
+#endif /* HAVE_RESPONSE_TIME_DISTRIBUTION */
+
+#endif // QUERY_RESPONSE_TIME_H
diff -ruN a/sql/set_var.cc b/sql/set_var.cc
--- a/sql/set_var.cc	2010-11-01 08:43:57.000000000 +0000
+++ b/sql/set_var.cc	2010-11-01 08:52:40.000000000 +0000
@@ -1017,6 +1017,14 @@
 static sys_var_use_global_long_query_time sys_use_global_long_query_time;
 static sys_var_bool_ptr       sys_slow_query_log_microseconds_timestamp(&vars, "slow_query_log_microseconds_timestamp",
                                                        &opt_slow_query_log_microseconds_timestamp);
+#ifdef HAVE_RESPONSE_TIME_DISTRIBUTION
+static sys_var_bool_ptr       sys_enable_query_response_time_stats(&vars, "enable_query_response_time_stats",
+                                                       &opt_enable_query_response_time_stats);
+static sys_var_long_ptr       sys_query_response_time_range_base(&vars, "query_response_time_range_base",
+					               &opt_query_response_time_range_base);
+#endif /* HAVE_RESPONSE_TIME_DISTRIBUTION */
+static sys_var_have_variable sys_have_response_time_distribution(&vars, "have_response_time_distribution",
+                                                       &have_response_time_distribution);
 /* Synonym of "slow_query_log" for consistency with SHOW VARIABLES output */
 static sys_var_log_state sys_var_log_slow(&vars, "log_slow_queries",
                                           &opt_slow_log, QUERY_LOG_SLOW);
diff -ruN a/sql/sql_parse.cc b/sql/sql_parse.cc
--- a/sql/sql_parse.cc	2010-11-01 08:43:57.000000000 +0000
+++ b/sql/sql_parse.cc	2010-11-01 08:52:40.000000000 +0000
@@ -28,6 +28,7 @@
 #include "events.h"
 #include "sql_trigger.h"
 #include "debug_sync.h"
+#include "query_response_time.h"
 
 /**
   @defgroup Runtime_Environment Runtime Environment
@@ -1764,23 +1765,37 @@
     Do not log administrative statements unless the appropriate option is
     set.
   */
+#ifdef HAVE_RESPONSE_TIME_DISTRIBUTION
+  if (opt_enable_query_response_time_stats || thd->enable_slow_log)
+#else /* HAVE_RESPONSE_TIME_DISTRIBUTION */
   if (thd->enable_slow_log)
+#endif /* HAVE_RESPONSE_TIME_DISTRIBUTION */
   {
-    ulonglong end_utime_of_query= thd->current_utime();
-    thd_proc_info(thd, "logging slow query");
-
-    if (((end_utime_of_query - thd->utime_after_lock) >
-         thd->variables.long_query_time ||
-         ((thd->server_status &
-           (SERVER_QUERY_NO_INDEX_USED | SERVER_QUERY_NO_GOOD_INDEX_USED)) &&
-          opt_log_queries_not_using_indexes &&
-           !(sql_command_flags[thd->lex->sql_command] & CF_STATUS_COMMAND))) &&
-        thd->examined_row_count >= thd->variables.min_examined_row_limit)
+    ulonglong end_utime_of_query   = thd->current_utime();
+    ulonglong query_execution_time = end_utime_of_query - thd->utime_after_lock;
+    #ifdef HAVE_RESPONSE_TIME_DISTRIBUTION
+    if(opt_enable_query_response_time_stats)
+    {
+      query_response_time_collect(query_execution_time);
+    }
+    #endif /* HAVE_RESPONSE_TIME_DISTRIBUTION */
+    if (thd->enable_slow_log)
     {
       thd_proc_info(thd, "logging slow query");
-      thd->status_var.long_query_count++;
-      slow_log_print(thd, thd->query(), thd->query_length(), 
-                     end_utime_of_query);
+
+      if ((query_execution_time >
+           thd->variables.long_query_time ||
+           ((thd->server_status &
+             (SERVER_QUERY_NO_INDEX_USED | SERVER_QUERY_NO_GOOD_INDEX_USED)) &&
+            opt_log_queries_not_using_indexes &&
+             !(sql_command_flags[thd->lex->sql_command] & CF_STATUS_COMMAND))) &&
+          thd->examined_row_count >= thd->variables.min_examined_row_limit)
+      {
+        thd_proc_info(thd, "logging slow query");
+        thd->status_var.long_query_count++;
+        slow_log_print(thd, thd->query(), thd->query_length(), 
+                       end_utime_of_query);
+      }
     }
   }
   DBUG_VOID_RETURN;
@@ -1905,6 +1920,7 @@
   case SCH_CHARSETS:
   case SCH_ENGINES:
   case SCH_COLLATIONS:
+  case SCH_QUERY_RESPONSE_TIME:
   case SCH_COLLATION_CHARACTER_SET_APPLICABILITY:
   case SCH_USER_PRIVILEGES:
   case SCH_SCHEMA_PRIVILEGES:
@@ -7264,6 +7280,12 @@
     init_global_index_stats();
     pthread_mutex_unlock(&LOCK_global_index_stats);
   }
+#ifdef HAVE_RESPONSE_TIME_DISTRIBUTION
+  if (options & REFRESH_QUERY_RESPONSE_TIME)
+  {
+    query_response_time_flush();
+  }
+#endif /* HAVE_RESPONSE_TIME_DISTRIBUTION */
   if (options & (REFRESH_USER_STATS | REFRESH_CLIENT_STATS | REFRESH_THREAD_STATS))
   {
     pthread_mutex_lock(&LOCK_global_user_client_stats);
diff -ruN a/sql/sql_show.cc b/sql/sql_show.cc
--- a/sql/sql_show.cc	2010-11-01 08:43:53.000000000 +0000
+++ b/sql/sql_show.cc	2010-11-01 08:52:40.000000000 +0000
@@ -31,6 +31,7 @@
 #include "event_data_objects.h"
 #endif
 #include <my_dir.h>
+#include "query_response_time.h"
 #include "debug_sync.h"
 
 #define STR_OR_NIL(S) ((S) ? (S) : "<nil>")
@@ -7533,6 +7534,13 @@
 
 */
 
+ST_FIELD_INFO query_response_time_fields_info[] =
+  {
+    {"time",  QRT_TIME_STRING_LENGTH,      MYSQL_TYPE_STRING,  0, 0,            "", SKIP_OPEN_TABLE },
+    {"count", MY_INT32_NUM_DECIMAL_DIGITS, MYSQL_TYPE_LONG, 0, MY_I_S_UNSIGNED, "", SKIP_OPEN_TABLE },
+    {"total",  QRT_TIME_STRING_LENGTH,     MYSQL_TYPE_STRING,  0, 0,            "", SKIP_OPEN_TABLE },
+    {0,       0,                           MYSQL_TYPE_STRING,  0, 0,             0, SKIP_OPEN_TABLE }
+  };
 ST_SCHEMA_TABLE schema_tables[]=
 {
   {"CHARACTER_SETS", charsets_fields_info, create_schema_table, 
@@ -7587,6 +7595,13 @@
    1, 9, 0, OPEN_TABLE_ONLY},
   {"ROUTINES", proc_fields_info, create_schema_table, 
    fill_schema_proc, make_proc_old_format, 0, -1, -1, 0, 0},
+#ifdef HAVE_RESPONSE_TIME_DISTRIBUTION
+  {"QUERY_RESPONSE_TIME", query_response_time_fields_info, create_schema_table, 
+   query_response_time_fill, make_old_format, 0, -1, -1, 0, 0},
+#else /* HAVE_RESPONSE_TIME_DISTRIBUTION */
+  {"QUERY_RESPONSE_TIME", query_response_time_fields_info, create_schema_table, 
+   0, make_old_format, 0, -1, -1, 0, 0},
+#endif /* HAVE_RESPONSE_TIME_DISTRIBUTION */
   {"SCHEMATA", schema_fields_info, create_schema_table,
    fill_schema_schemata, make_schemata_old_format, 0, 1, -1, 0, 0},
   {"SCHEMA_PRIVILEGES", schema_privileges_fields_info, create_schema_table,
diff -ruN a/sql/sql_yacc.yy b/sql/sql_yacc.yy
--- a/sql/sql_yacc.yy	2010-11-01 08:43:53.000000000 +0000
+++ b/sql/sql_yacc.yy	2010-11-01 08:52:40.000000000 +0000
@@ -1079,6 +1079,7 @@
 %token  PURGE
 %token  QUARTER_SYM
 %token  QUERY_SYM
+%token  QUERY_RESPONSE_TIME_SYM
 %token  QUICK
 %token  RANGE_SYM                     /* SQL-2003-R */
 %token  READS_SYM                     /* SQL-2003-R */
@@ -10396,6 +10397,15 @@
            if (prepare_schema_table(YYTHD, lex, 0, SCH_INDEX_STATS))
              MYSQL_YYABORT;
           }
+        | QUERY_RESPONSE_TIME_SYM wild_and_where
+	  {
+#ifdef HAVE_RESPONSE_TIME_DISTRIBUTION
+           LEX *lex= Lex;
+           lex->sql_command= SQLCOM_SELECT;
+           if (prepare_schema_table(YYTHD, lex, 0, SCH_QUERY_RESPONSE_TIME))
+             MYSQL_YYABORT;	  
+#endif /* HAVE_RESPONSE_TIME_DISTRIBUTION */
+	  }
         | CREATE PROCEDURE sp_name
           {
             LEX *lex= Lex;
@@ -10616,6 +10626,12 @@
           { Lex->type|= REFRESH_TABLE_STATS; }
         | INDEX_STATS_SYM
           { Lex->type|= REFRESH_INDEX_STATS; }
+        | QUERY_RESPONSE_TIME_SYM
+          { 
+#ifdef HAVE_RESPONSE_TIME_DISTRIBUTION
+            Lex->type|= REFRESH_QUERY_RESPONSE_TIME; 
+#endif /* HAVE_RESPONSE_TIME_DISTRIBUTION */
+          }
         | MASTER_SYM
           { Lex->type|= REFRESH_MASTER; }
         | DES_KEY_FILE
@@ -11895,6 +11911,7 @@
         | PROFILES_SYM             {}
         | QUARTER_SYM              {}
         | QUERY_SYM                {}
+        | QUERY_RESPONSE_TIME_SYM  {}
         | QUICK                    {}
         | READ_ONLY_SYM            {}
         | REBUILD_SYM              {}
diff -ruN a/sql/table.h b/sql/table.h
--- a/sql/table.h	2010-11-01 08:43:53.000000000 +0000
+++ b/sql/table.h	2010-11-01 08:52:40.000000000 +0000
@@ -964,6 +964,7 @@
   SCH_PROFILES,
   SCH_REFERENTIAL_CONSTRAINTS,
   SCH_PROCEDURES,
+  SCH_QUERY_RESPONSE_TIME,
   SCH_SCHEMATA,
   SCH_SCHEMA_PRIVILEGES,
   SCH_SESSION_STATUS,
diff -ruN a/configure.in b/configure.in
--- a/configure.in	2010-12-07 19:19:42.000000000 +0300
+++ b/configure.in	2010-12-07 19:21:39.000000000 +0300
@@ -1738,6 +1738,7 @@
   int main()
   {
     int foo= -10; int bar= 10;
+    long long int foo64= -10; long long int bar64= 10;
     if (!__sync_fetch_and_add(&foo, bar) || foo)
       return -1;
     bar= __sync_lock_test_and_set(&foo, bar);
@@ -1746,6 +1747,14 @@
     bar= __sync_val_compare_and_swap(&bar, foo, 15);
     if (bar)
       return -1;
+    if (!__sync_fetch_and_add(&foo64, bar64) || foo64)
+      return -1;
+    bar64= __sync_lock_test_and_set(&foo64, bar64);
+    if (bar64 || foo64 != 10)
+      return -1;
+    bar64= __sync_val_compare_and_swap(&bar64, foo, 15);
+    if (bar64)
+      return -1;
     return 0;
   }
 ], [mysql_cv_gcc_atomic_builtins=yes],
@@ -1757,6 +1766,46 @@
             [Define to 1 if compiler provides atomic builtins.])
 fi
 
+AC_CACHE_CHECK([whether the OS provides atomic_* functions like Solaris],
+               [mysql_cv_solaris_atomic],
+  [AC_RUN_IFELSE(
+     [AC_LANG_PROGRAM(
+        [[
+        #include <atomic.h>
+        ]],
+     [[
+        int foo = -10; int bar = 10;
+        int64_t foo64 = -10; int64_t bar64 = 10;
+        if (atomic_add_int_nv((uint_t *)&foo, bar) || foo)
+          return -1;
+        bar = atomic_swap_uint((uint_t *)&foo, (uint_t)bar);
+        if (bar || foo != 10)
+          return -1;
+        bar = atomic_cas_uint((uint_t *)&bar, (uint_t)foo, 15);
+        if (bar)
+          return -1;
+        if (atomic_add_64_nv((volatile uint64_t *)&foo64, bar64) || foo64)
+          return -1;
+        bar64 = atomic_swap_64((volatile uint64_t *)&foo64, (uint64_t)bar64);
+        if (bar64 || foo64 != 10)
+          return -1;
+        bar64 = atomic_cas_64((volatile uint64_t *)&bar64, (uint_t)foo64, 15);
+        if (bar64)
+          return -1;
+        atomic_or_64((volatile uint64_t *)&bar64, 0);
+        return 0;
+     ]]
+     )],
+   [mysql_cv_solaris_atomic=yes],
+   [mysql_cv_solaris_atomic=no],
+   [mysql_cv_solaris_atomic=no]
+)])
+
+if test "x$mysql_cv_solaris_atomic" = xyes; then
+  AC_DEFINE(HAVE_SOLARIS_ATOMIC, 1,
+            [Define to 1 if OS provides atomic_* functions like Solaris.])
+fi
+
 # Force static compilation to avoid linking problems/get more speed
 AC_ARG_WITH(mysqld-ldflags,
     [  --with-mysqld-ldflags   Extra linking arguments for mysqld],
@@ -2683,7 +2732,16 @@
 AC_SUBST(readline_link)
 AC_SUBST(readline_h_ln_cmd)
 
+AC_ARG_WITH(response_time_distribution,
+    AC_HELP_STRING([--without-response_time_distribution],[Disable response_time_distribution feature.]),
+    [with_response_time_distribution=$withval],
+    [with_response_time_distribution=yes]
+)
 
+if test "$with_response_time_distribution" = "yes"
+then
+  AC_DEFINE([HAVE_RESPONSE_TIME_DISTRIBUTION], [1], [If we want to have response_time_distribution])
+fi
 
 # Include man pages, if desired, adapted to the configured parts.
 if test X"$with_man" = Xyes
diff -ruN /dev/null b/include/my_atomic.h
--- /dev/null	1970-01-01 00:00:00.000000000 +0000
+++ b/include/my_atomic.h	2011-06-07 08:59:00.000000000 +0300
@@ -0,0 +1,287 @@
+#ifndef MY_ATOMIC_INCLUDED
+#define MY_ATOMIC_INCLUDED
+
+/* Copyright (C) 2006 MySQL AB
+
+   This program is free software; you can redistribute it and/or modify
+   it under the terms of the GNU General Public License as published by
+   the Free Software Foundation; version 2 of the License.
+
+   This program is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+   GNU General Public License for more details.
+
+   You should have received a copy of the GNU General Public License
+   along with this program; if not, write to the Free Software
+   Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA */
+
+/*
+  This header defines five atomic operations:
+
+  my_atomic_add#(&var, what)
+    'Fetch and Add'
+    add 'what' to *var, and return the old value of *var
+
+  my_atomic_fas#(&var, what)
+    'Fetch And Store'
+    store 'what' in *var, and return the old value of *var
+
+  my_atomic_cas#(&var, &old, new)
+    An odd variation of 'Compare And Set/Swap'
+    if *var is equal to *old, then store 'new' in *var, and return TRUE
+    otherwise store *var in *old, and return FALSE
+    Usually, &old should not be accessed if the operation is successful.
+
+  my_atomic_load#(&var)
+    return *var
+
+  my_atomic_store#(&var, what)
+    store 'what' in *var
+
+  '#' is substituted by a size suffix - 8, 16, 32, 64, or ptr
+  (e.g. my_atomic_add8, my_atomic_fas32, my_atomic_casptr).
+
+  NOTE This operations are not always atomic, so they always must be
+  enclosed in my_atomic_rwlock_rdlock(lock)/my_atomic_rwlock_rdunlock(lock)
+  or my_atomic_rwlock_wrlock(lock)/my_atomic_rwlock_wrunlock(lock).
+  Hint: if a code block makes intensive use of atomic ops, it make sense
+  to take/release rwlock once for the whole block, not for every statement.
+
+  On architectures where these operations are really atomic, rwlocks will
+  be optimized away.
+  8- and 16-bit atomics aren't implemented for windows (see generic-msvc.h),
+  but can be added, if necessary. 
+*/
+
+#ifndef my_atomic_rwlock_init
+
+#define intptr         void *
+/**
+  Currently we don't support 8-bit and 16-bit operations.
+  It can be added later if needed.
+*/
+#undef MY_ATOMIC_HAS_8_16
+
+#ifndef MY_ATOMIC_MODE_RWLOCKS
+/*
+ * Attempt to do atomic ops without locks
+ */
+#include "atomic/nolock.h"
+#endif
+
+#ifndef make_atomic_cas_body
+/* nolock.h was not able to generate even a CAS function, fall back */
+#include "atomic/rwlock.h"
+#endif
+
+/* define missing functions by using the already generated ones */
+#ifndef make_atomic_add_body
+#define make_atomic_add_body(S)                                 \
+  int ## S tmp=*a;                                              \
+  while (!my_atomic_cas ## S(a, &tmp, tmp+v)) ;                 \
+  v=tmp;
+#endif
+#ifndef make_atomic_fas_body
+#define make_atomic_fas_body(S)                                 \
+  int ## S tmp=*a;                                              \
+  while (!my_atomic_cas ## S(a, &tmp, v)) ;                     \
+  v=tmp;
+#endif
+#ifndef make_atomic_load_body
+#define make_atomic_load_body(S)                                \
+  ret= 0; /* avoid compiler warning */                          \
+  (void)(my_atomic_cas ## S(a, &ret, ret));
+#endif
+#ifndef make_atomic_store_body
+#define make_atomic_store_body(S)                               \
+  (void)(my_atomic_fas ## S (a, v));
+#endif
+
+/*
+  transparent_union doesn't work in g++
+  Bug ?
+
+  Darwin's gcc doesn't want to put pointers in a transparent_union
+  when built with -arch ppc64. Complains:
+  warning: 'transparent_union' attribute ignored
+*/
+#if defined(__GNUC__) && !defined(__cplusplus) && \
+      ! (defined(__APPLE__) && (defined(_ARCH_PPC64) ||defined (_ARCH_PPC)))
+/*
+  we want to be able to use my_atomic_xxx functions with
+  both signed and unsigned integers. But gcc will issue a warning
+  "passing arg N of `my_atomic_XXX' as [un]signed due to prototype"
+  if the signedness of the argument doesn't match the prototype, or
+  "pointer targets in passing argument N of my_atomic_XXX differ in signedness"
+  if int* is used where uint* is expected (or vice versa).
+  Let's shut these warnings up
+*/
+#define make_transparent_unions(S)                              \
+        typedef union {                                         \
+          int  ## S  i;                                         \
+          uint ## S  u;                                         \
+        } U_ ## S   __attribute__ ((transparent_union));        \
+        typedef union {                                         \
+          int  ## S volatile *i;                                \
+          uint ## S volatile *u;                                \
+        } Uv_ ## S   __attribute__ ((transparent_union));
+#define uintptr intptr
+make_transparent_unions(8)
+make_transparent_unions(16)
+make_transparent_unions(32)
+make_transparent_unions(64)
+make_transparent_unions(ptr)
+#undef uintptr
+#undef make_transparent_unions
+#define a       U_a.i
+#define cmp     U_cmp.i
+#define v       U_v.i
+#define set     U_set.i
+#else
+#define U_8    int8
+#define U_16   int16
+#define U_32   int32
+#define U_64   int64
+#define U_ptr  intptr
+#define Uv_8   int8
+#define Uv_16  int16
+#define Uv_32  int32
+#define Uv_64  int64
+#define Uv_ptr intptr
+#define U_a    volatile *a
+#define U_cmp  *cmp
+#define U_v    v
+#define U_set  set
+#endif /* __GCC__ transparent_union magic */
+
+#define make_atomic_cas(S)                                      \
+static inline int my_atomic_cas ## S(Uv_ ## S U_a,              \
+                            Uv_ ## S U_cmp, U_ ## S U_set)      \
+{                                                               \
+  int8 ret;                                                     \
+  make_atomic_cas_body(S);                                      \
+  return ret;                                                   \
+}
+
+#define make_atomic_add(S)                                      \
+static inline int ## S my_atomic_add ## S(                      \
+                        Uv_ ## S U_a, U_ ## S U_v)              \
+{                                                               \
+  make_atomic_add_body(S);                                      \
+  return v;                                                     \
+}
+
+#define make_atomic_fas(S)                                      \
+static inline int ## S my_atomic_fas ## S(                      \
+                         Uv_ ## S U_a, U_ ## S U_v)             \
+{                                                               \
+  make_atomic_fas_body(S);                                      \
+  return v;                                                     \
+}
+
+#define make_atomic_load(S)                                     \
+static inline int ## S my_atomic_load ## S(Uv_ ## S U_a)        \
+{                                                               \
+  int ## S ret;                                                 \
+  make_atomic_load_body(S);                                     \
+  return ret;                                                   \
+}
+
+#define make_atomic_store(S)                                    \
+static inline void my_atomic_store ## S(                        \
+                     Uv_ ## S U_a, U_ ## S U_v)                 \
+{                                                               \
+  make_atomic_store_body(S);                                    \
+}
+
+#ifdef MY_ATOMIC_HAS_8_16
+make_atomic_cas(8)
+make_atomic_cas(16)
+#endif
+make_atomic_cas(32)
+make_atomic_cas(64)
+make_atomic_cas(ptr)
+
+#ifdef MY_ATOMIC_HAS_8_16
+make_atomic_add(8)
+make_atomic_add(16)
+#endif
+make_atomic_add(32)
+make_atomic_add(64)
+
+#ifdef MY_ATOMIC_HAS_8_16
+make_atomic_load(8)
+make_atomic_load(16)
+#endif
+make_atomic_load(32)
+make_atomic_load(64)
+make_atomic_load(ptr)
+
+#ifdef MY_ATOMIC_HAS_8_16
+make_atomic_fas(8)
+make_atomic_fas(16)
+#endif
+make_atomic_fas(32)
+make_atomic_fas(64)
+make_atomic_fas(ptr)
+
+#ifdef MY_ATOMIC_HAS_8_16
+make_atomic_store(8)
+make_atomic_store(16)
+#endif
+make_atomic_store(32)
+make_atomic_store(64)
+make_atomic_store(ptr)
+
+#ifdef _atomic_h_cleanup_
+#include _atomic_h_cleanup_
+#undef _atomic_h_cleanup_
+#endif
+
+#undef U_8
+#undef U_16
+#undef U_32
+#undef U_64
+#undef U_ptr
+#undef Uv_8
+#undef Uv_16
+#undef Uv_32
+#undef Uv_64
+#undef Uv_ptr
+#undef a
+#undef cmp
+#undef v
+#undef set
+#undef U_a
+#undef U_cmp
+#undef U_v
+#undef U_set
+#undef make_atomic_add
+#undef make_atomic_cas
+#undef make_atomic_load
+#undef make_atomic_store
+#undef make_atomic_fas
+#undef make_atomic_add_body
+#undef make_atomic_cas_body
+#undef make_atomic_load_body
+#undef make_atomic_store_body
+#undef make_atomic_fas_body
+#undef intptr
+
+/*
+  the macro below defines (as an expression) the code that
+  will be run in spin-loops. Intel manuals recummend to have PAUSE there.
+  It is expected to be defined in include/atomic/ *.h files
+*/
+#ifndef LF_BACKOFF
+#define LF_BACKOFF (1)
+#endif
+
+#define MY_ATOMIC_OK       0
+#define MY_ATOMIC_NOT_1CPU 1
+extern int my_atomic_initialize();
+
+#endif
+
+#endif /* MY_ATOMIC_INCLUDED */
diff -ruN a/mysys/Makefile.am b/mysys/Makefile.am
--- a/mysys/Makefile.am	2011-04-12 15:11:35.000000000 +0300
+++ b/mysys/Makefile.am	2011-06-07 08:59:00.432197996 +0300
@@ -51,7 +51,8 @@
 			rijndael.c my_aes.c sha1.c \
 			my_compare.c my_netware.c my_largepage.c \
 			my_memmem.c stacktrace.c \
-			my_windac.c my_access.c base64.c my_libwrap.c
+			my_windac.c my_access.c base64.c my_libwrap.c \
+			my_atomic.c
 
 if NEED_THREAD
 # mf_keycache is used only in the server, so it is safe to leave the file
diff -ruN a/mysys/CMakeLists.txt b/mysys/CMakeLists.txt
--- a/mysys/CMakeLists.txt	2011-04-12 15:11:35.000000000 +0300
+++ b/mysys/CMakeLists.txt	2011-06-07 08:59:00.432197996 +0300
@@ -41,7 +41,8 @@
 				my_static.c my_symlink.c my_symlink2.c my_sync.c my_thr_init.c my_wincond.c
 				my_windac.c my_winthread.c my_write.c ptr_cmp.c queues.c stacktrace.c
 				rijndael.c safemalloc.c sha1.c string.c thr_alarm.c thr_lock.c thr_mutex.c
-				thr_rwlock.c tree.c typelib.c my_vle.c base64.c my_memmem.c my_getpagesize.c)
+				thr_rwlock.c tree.c typelib.c my_vle.c base64.c my_memmem.c my_getpagesize.c
+                                my_atomic.c)
 
 IF(NOT SOURCE_SUBLIBS)
   ADD_LIBRARY(mysys ${MYSYS_SOURCES})
diff -ruN a/include/Makefile.am b/include/Makefile.am
--- a/include/Makefile.am	2011-04-12 15:11:35.000000000 +0300
+++ b/include/Makefile.am	2011-06-07 08:59:00.432197996 +0300
@@ -38,7 +38,10 @@
 			my_aes.h my_tree.h my_trie.h hash.h thr_alarm.h \
 			thr_lock.h t_ctype.h violite.h my_md5.h base64.h \
 			my_compare.h my_time.h my_vle.h my_user.h \
-			my_libwrap.h my_stacktrace.h
+			my_libwrap.h my_stacktrace.h my_atomic.h \
+			atomic/gcc_builtins.h atomic/generic-msvc.h \
+			atomic/nolock.h atomic/rwlock.h atomic/solaris.h \
+			atomic/x86-gcc.h
 
 EXTRA_DIST =        mysql.h.pp mysql/plugin.h.pp
 
diff -ruN /dev/null b/include/atomic/gcc_builtins.h
--- /dev/null	1970-01-01 00:00:00.000000000 +0000
+++ b/include/atomic/gcc_builtins.h	2011-06-07 08:59:00.000000000 +0300
@@ -0,0 +1,42 @@
+#ifndef ATOMIC_GCC_BUILTINS_INCLUDED
+#define ATOMIC_GCC_BUILTINS_INCLUDED
+
+/* Copyright (C) 2008 MySQL AB
+
+   This program is free software; you can redistribute it and/or modify
+   it under the terms of the GNU General Public License as published by
+   the Free Software Foundation; version 2 of the License.
+
+   This program is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+   GNU General Public License for more details.
+
+   You should have received a copy of the GNU General Public License
+   along with this program; if not, write to the Free Software
+   Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA */
+
+#define make_atomic_add_body(S)                     \
+  v= __sync_fetch_and_add(a, v);
+#define make_atomic_fas_body(S)                     \
+  v= __sync_lock_test_and_set(a, v);
+#define make_atomic_cas_body(S)                     \
+  int ## S sav;                                     \
+  int ## S cmp_val= *cmp;                           \
+  sav= __sync_val_compare_and_swap(a, cmp_val, set);\
+  if (!(ret= (sav == cmp_val))) *cmp= sav
+
+#ifdef MY_ATOMIC_MODE_DUMMY
+#define make_atomic_load_body(S)   ret= *a
+#define make_atomic_store_body(S)  *a= v
+#define MY_ATOMIC_MODE "gcc-builtins-up"
+
+#else
+#define MY_ATOMIC_MODE "gcc-builtins-smp"
+#define make_atomic_load_body(S)                    \
+  ret= __sync_fetch_and_or(a, 0);
+#define make_atomic_store_body(S)                   \
+  (void) __sync_lock_test_and_set(a, v);
+#endif
+
+#endif /* ATOMIC_GCC_BUILTINS_INCLUDED */
diff -ruN /dev/null b/include/atomic/generic-msvc.h
--- /dev/null	1970-01-01 00:00:00.000000000 +0000
+++ b/include/atomic/generic-msvc.h	2011-06-07 08:59:00.000000000 +0300
@@ -0,0 +1,134 @@
+/* Copyright (C) 2006-2008 MySQL AB, 2008-2009 Sun Microsystems, Inc.
+
+   This program is free software; you can redistribute it and/or modify
+   it under the terms of the GNU General Public License as published by
+   the Free Software Foundation; version 2 of the License.
+
+   This program is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+   GNU General Public License for more details.
+
+   You should have received a copy of the GNU General Public License
+   along with this program; if not, write to the Free Software
+   Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA */
+
+#ifndef _atomic_h_cleanup_
+#define _atomic_h_cleanup_ "atomic/generic-msvc.h"
+
+/*
+  We don't implement anything specific for MY_ATOMIC_MODE_DUMMY, always use
+  intrinsics.
+  8 and 16-bit atomics are not implemented, but it can be done if necessary.
+*/
+#undef MY_ATOMIC_HAS_8_16
+
+#include <windows.h>
+/*
+  x86 compilers (both VS2003 or VS2005) never use instrinsics, but generate 
+  function calls to kernel32 instead, even in the optimized build. 
+  We force intrinsics as described in MSDN documentation for 
+  _InterlockedCompareExchange.
+*/
+#ifdef _M_IX86
+
+#if (_MSC_VER >= 1500)
+#include <intrin.h>
+#else
+C_MODE_START
+/*Visual Studio 2003 and earlier do not have prototypes for atomic intrinsics*/
+LONG _InterlockedCompareExchange (LONG volatile *Target, LONG Value, LONG Comp);
+LONGLONG _InterlockedCompareExchange64 (LONGLONG volatile *Target,
+                                        LONGLONG Value, LONGLONG Comp);
+C_MODE_END
+
+#pragma intrinsic(_InterlockedCompareExchange)
+#pragma intrinsic(_InterlockedCompareExchange64)
+#endif
+
+#define InterlockedCompareExchange _InterlockedCompareExchange
+#define InterlockedCompareExchange64 _InterlockedCompareExchange64
+/*
+ No need to do something special for InterlockedCompareExchangePointer
+ as it is a #define to InterlockedCompareExchange. The same applies to
+ InterlockedExchangePointer. 
+*/
+#endif /*_M_IX86*/
+
+#define MY_ATOMIC_MODE "msvc-intrinsics"
+/* Implement using CAS on WIN32 */
+#define IL_COMP_EXCHG32(X,Y,Z)  \
+  InterlockedCompareExchange((volatile LONG *)(X),(Y),(Z))
+#define IL_COMP_EXCHG64(X,Y,Z)  \
+  InterlockedCompareExchange64((volatile LONGLONG *)(X), \
+                               (LONGLONG)(Y),(LONGLONG)(Z))
+#define IL_COMP_EXCHGptr        InterlockedCompareExchangePointer
+
+#define make_atomic_cas_body(S)                                 \
+  int ## S initial_cmp= *cmp;                                   \
+  int ## S initial_a= IL_COMP_EXCHG ## S (a, set, initial_cmp); \
+  if (!(ret= (initial_a == initial_cmp))) *cmp= initial_a;
+
+#ifndef _M_IX86
+/* Use full set of optimised functions on WIN64 */
+#define IL_EXCHG_ADD32(X,Y)     \
+  InterlockedExchangeAdd((volatile LONG *)(X),(Y))
+#define IL_EXCHG_ADD64(X,Y)     \
+  InterlockedExchangeAdd64((volatile LONGLONG *)(X),(LONGLONG)(Y))
+#define IL_EXCHG32(X,Y)         \
+  InterlockedExchange((volatile LONG *)(X),(Y))
+#define IL_EXCHG64(X,Y)         \
+  InterlockedExchange64((volatile LONGLONG *)(X),(LONGLONG)(Y))
+#define IL_EXCHGptr             InterlockedExchangePointer
+
+#define make_atomic_add_body(S) \
+  v= IL_EXCHG_ADD ## S (a, v)
+#define make_atomic_swap_body(S) \
+  v= IL_EXCHG ## S (a, v)
+#define make_atomic_load_body(S)       \
+  ret= 0; /* avoid compiler warning */ \
+  ret= IL_COMP_EXCHG ## S (a, ret, ret);
+#endif
+/*
+  my_yield_processor (equivalent of x86 PAUSE instruction) should be used
+  to improve performance on hyperthreaded CPUs. Intel recommends to use it in
+  spin loops also on non-HT machines to reduce power consumption (see e.g 
+  http://softwarecommunity.intel.com/articles/eng/2004.htm)
+
+  Running benchmarks for spinlocks implemented with InterlockedCompareExchange
+  and YieldProcessor shows that much better performance is achieved by calling
+  YieldProcessor in a loop - that is, yielding longer. On Intel boxes setting
+  loop count in the range 200-300 brought best results.
+ */
+#ifndef YIELD_LOOPS
+#define YIELD_LOOPS 200
+#endif
+
+static __inline int my_yield_processor()
+{
+  int i;
+  for(i=0; i<YIELD_LOOPS; i++)
+  {
+#if (_MSC_VER <= 1310)
+    /* On older compilers YieldProcessor is not available, use inline assembly*/
+    __asm { rep nop }
+#else
+    YieldProcessor();
+#endif
+  }
+  return 1;
+}
+
+#define LF_BACKOFF my_yield_processor()
+#else /* cleanup */
+
+#undef IL_EXCHG_ADD32
+#undef IL_EXCHG_ADD64
+#undef IL_COMP_EXCHG32
+#undef IL_COMP_EXCHG64
+#undef IL_COMP_EXCHGptr
+#undef IL_EXCHG32
+#undef IL_EXCHG64
+#undef IL_EXCHGptr
+
+#endif
diff -ruN /dev/null b/include/atomic/nolock.h
--- /dev/null	1970-01-01 00:00:00.000000000 +0000
+++ b/include/atomic/nolock.h	2011-06-07 08:59:00.000000000 +0300
@@ -0,0 +1,69 @@
+#ifndef ATOMIC_NOLOCK_INCLUDED
+#define ATOMIC_NOLOCK_INCLUDED
+
+/* Copyright (C) 2006 MySQL AB
+
+   This program is free software; you can redistribute it and/or modify
+   it under the terms of the GNU General Public License as published by
+   the Free Software Foundation; version 2 of the License.
+
+   This program is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+   GNU General Public License for more details.
+
+   You should have received a copy of the GNU General Public License
+   along with this program; if not, write to the Free Software
+   Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA */
+
+#if defined(__i386__) || defined(_MSC_VER) || defined(__x86_64__)   \
+    || defined(HAVE_GCC_ATOMIC_BUILTINS) \
+    || defined(HAVE_SOLARIS_ATOMIC)
+
+#  ifdef MY_ATOMIC_MODE_DUMMY
+#    define LOCK_prefix ""
+#  else
+#    define LOCK_prefix "lock"
+#  endif
+/*
+  We choose implementation as follows:
+  ------------------------------------
+  On Windows using Visual C++ the native implementation should be
+  preferrable. When using gcc we prefer the Solaris implementation
+  before the gcc because of stability preference, we choose gcc
+  builtins if available, otherwise we choose the somewhat broken
+  native x86 implementation. If neither Visual C++ or gcc we still
+  choose the Solaris implementation on Solaris (mainly for SunStudio
+  compilers).
+*/
+#  if defined(_MSV_VER)
+#    include "generic-msvc.h"
+#  elif __GNUC__
+#    if defined(HAVE_SOLARIS_ATOMIC)
+#      include "solaris.h"
+#    elif defined(HAVE_GCC_ATOMIC_BUILTINS)
+#      include "gcc_builtins.h"
+#    elif defined(__i386__) || defined(__x86_64__)
+#      include "x86-gcc.h"
+#    endif
+#  elif defined(HAVE_SOLARIS_ATOMIC)
+#    include "solaris.h"
+#  endif
+#endif
+
+#if defined(make_atomic_cas_body)
+/*
+  Type not used so minimal size (emptry struct has different size between C
+  and C++, zero-length array is gcc-specific).
+*/
+typedef char my_atomic_rwlock_t __attribute__ ((unused));
+#define my_atomic_rwlock_destroy(name)
+#define my_atomic_rwlock_init(name)
+#define my_atomic_rwlock_rdlock(name)
+#define my_atomic_rwlock_wrlock(name)
+#define my_atomic_rwlock_rdunlock(name)
+#define my_atomic_rwlock_wrunlock(name)
+
+#endif
+
+#endif /* ATOMIC_NOLOCK_INCLUDED */
diff -ruN /dev/null b/include/atomic/rwlock.h
--- /dev/null	1970-01-01 00:00:00.000000000 +0000
+++ b/include/atomic/rwlock.h	2011-06-07 08:59:00.000000000 +0300
@@ -0,0 +1,100 @@
+#ifndef ATOMIC_RWLOCK_INCLUDED
+#define ATOMIC_RWLOCK_INCLUDED
+
+/* Copyright (C) 2006 MySQL AB, 2009 Sun Microsystems, Inc.
+
+   This program is free software; you can redistribute it and/or modify
+   it under the terms of the GNU General Public License as published by
+   the Free Software Foundation; version 2 of the License.
+
+   This program is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+   GNU General Public License for more details.
+
+   You should have received a copy of the GNU General Public License
+   along with this program; if not, write to the Free Software
+   Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA */
+
+#define MY_ATOMIC_MODE_RWLOCKS 1
+
+#ifdef MY_ATOMIC_MODE_DUMMY
+/*
+  the following can never be enabled by ./configure, one need to put #define in
+  a source to trigger the following warning. The resulting code will be broken,
+  it only makes sense to do it to see now test_atomic detects broken
+  implementations (another way is to run a UP build on an SMP box).
+*/
+#warning MY_ATOMIC_MODE_DUMMY and MY_ATOMIC_MODE_RWLOCKS are incompatible
+
+typedef char my_atomic_rwlock_t;
+
+#define my_atomic_rwlock_destroy(name)
+#define my_atomic_rwlock_init(name)
+#define my_atomic_rwlock_rdlock(name)
+#define my_atomic_rwlock_wrlock(name)
+#define my_atomic_rwlock_rdunlock(name)
+#define my_atomic_rwlock_wrunlock(name)
+#define MY_ATOMIC_MODE "dummy (non-atomic)"
+#else /* not MY_ATOMIC_MODE_DUMMY */
+
+typedef struct {pthread_mutex_t rw;} my_atomic_rwlock_t;
+
+#ifndef SAFE_MUTEX
+
+/*
+  we're using read-write lock macros but map them to mutex locks, and they're
+  faster. Still, having semantically rich API we can change the
+  underlying implementation, if necessary.
+*/
+#define my_atomic_rwlock_destroy(name)     pthread_mutex_destroy(& (name)->rw)
+#define my_atomic_rwlock_init(name)        pthread_mutex_init(& (name)->rw, 0)
+#define my_atomic_rwlock_rdlock(name)      pthread_mutex_lock(& (name)->rw)
+#define my_atomic_rwlock_wrlock(name)      pthread_mutex_lock(& (name)->rw)
+#define my_atomic_rwlock_rdunlock(name)    pthread_mutex_unlock(& (name)->rw)
+#define my_atomic_rwlock_wrunlock(name)    pthread_mutex_unlock(& (name)->rw)
+
+#else /* SAFE_MUTEX */
+
+/*
+  SAFE_MUTEX pollutes the compiling name space with macros
+  that alter pthread_mutex_t, pthread_mutex_init, etc.
+  Atomic operations should never use the safe mutex wrappers.
+  Unfortunately, there is no way to have both:
+  - safe mutex macros expanding pthread_mutex_lock to safe_mutex_lock
+  - my_atomic macros expanding to unmodified pthread_mutex_lock
+  inlined in the same compilation unit.
+  So, in case of SAFE_MUTEX, a function call is required.
+  Given that SAFE_MUTEX is a debugging facility,
+  this extra function call is not a performance concern for
+  production builds.
+*/
+C_MODE_START
+extern void plain_pthread_mutex_init(safe_mutex_t *);
+extern void plain_pthread_mutex_destroy(safe_mutex_t *);
+extern void plain_pthread_mutex_lock(safe_mutex_t *);
+extern void plain_pthread_mutex_unlock(safe_mutex_t *);
+C_MODE_END
+
+#define my_atomic_rwlock_destroy(name)     plain_pthread_mutex_destroy(&(name)->rw)
+#define my_atomic_rwlock_init(name)        plain_pthread_mutex_init(&(name)->rw)
+#define my_atomic_rwlock_rdlock(name)      plain_pthread_mutex_lock(&(name)->rw)
+#define my_atomic_rwlock_wrlock(name)      plain_pthread_mutex_lock(&(name)->rw)
+#define my_atomic_rwlock_rdunlock(name)    plain_pthread_mutex_unlock(&(name)->rw)
+#define my_atomic_rwlock_wrunlock(name)    plain_pthread_mutex_unlock(&(name)->rw)
+
+#endif /* SAFE_MUTEX */
+
+#define MY_ATOMIC_MODE "mutex"
+#ifndef MY_ATOMIC_MODE_RWLOCKS
+#define MY_ATOMIC_MODE_RWLOCKS 1
+#endif
+#endif
+
+#define make_atomic_add_body(S)     int ## S sav; sav= *a; *a+= v; v=sav;
+#define make_atomic_fas_body(S)     int ## S sav; sav= *a; *a= v; v=sav;
+#define make_atomic_cas_body(S)     if ((ret= (*a == *cmp))) *a= set; else *cmp=*a;
+#define make_atomic_load_body(S)    ret= *a;
+#define make_atomic_store_body(S)   *a= v;
+
+#endif /* ATOMIC_RWLOCK_INCLUDED */
diff -ruN /dev/null b/include/atomic/solaris.h
--- /dev/null	1970-01-01 00:00:00.000000000 +0000
+++ b/include/atomic/solaris.h	2011-06-07 08:59:00.000000000 +0300
@@ -0,0 +1,72 @@
+/* Copyright (C) 2008 MySQL AB, 2009 Sun Microsystems, Inc
+
+   This program is free software; you can redistribute it and/or modify
+   it under the terms of the GNU General Public License as published by
+   the Free Software Foundation; version 2 of the License.
+
+   This program is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+   GNU General Public License for more details.
+
+   You should have received a copy of the GNU General Public License
+   along with this program; if not, write to the Free Software
+   Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA */
+
+#ifndef _atomic_h_cleanup_
+#define _atomic_h_cleanup_ "atomic/solaris.h"
+
+#include <atomic.h>
+
+#define	MY_ATOMIC_MODE	"solaris-atomic"
+
+#if defined(__GNUC__)
+#define atomic_typeof(T,V)      __typeof__(V)
+#else
+#define atomic_typeof(T,V)      T
+#endif
+
+#define uintptr_t void *
+#define atomic_or_ptr_nv(X,Y) (void *)atomic_or_ulong_nv((volatile ulong_t *)X, Y)
+
+#define make_atomic_cas_body(S)                         \
+  atomic_typeof(uint ## S ## _t, *cmp) sav;             \
+  sav = atomic_cas_ ## S(                               \
+           (volatile uint ## S ## _t *)a,               \
+           (uint ## S ## _t)*cmp,                       \
+           (uint ## S ## _t)set);                       \
+  if (! (ret= (sav == *cmp)))                           \
+    *cmp= sav;
+
+#define make_atomic_add_body(S)                         \
+  int ## S nv;  /* new value */                         \
+  nv= atomic_add_ ## S ## _nv((volatile uint ## S ## _t *)a, v); \
+  v= nv - v
+
+/* ------------------------------------------------------------------------ */
+
+#ifdef MY_ATOMIC_MODE_DUMMY
+
+#define make_atomic_load_body(S)  ret= *a
+#define make_atomic_store_body(S)   *a= v
+
+#else /* MY_ATOMIC_MODE_DUMMY */
+
+#define make_atomic_load_body(S)                        \
+  ret= atomic_or_ ## S ## _nv((volatile uint ## S ## _t *)a, 0)
+
+#define make_atomic_store_body(S)                       \
+  (void) atomic_swap_ ## S((volatile uint ## S ## _t *)a, (uint ## S ## _t)v)
+
+#endif
+
+#define make_atomic_fas_body(S)                        \
+  v= atomic_swap_ ## S((volatile uint ## S ## _t *)a, (uint ## S ## _t)v)
+
+#else /* cleanup */
+
+#undef uintptr_t
+#undef atomic_or_ptr_nv
+
+#endif
+
diff -ruN /dev/null b/include/atomic/x86-gcc.h
--- /dev/null	1970-01-01 00:00:00.000000000 +0000
+++ b/include/atomic/x86-gcc.h	2011-06-07 08:59:00.000000000 +0300
@@ -0,0 +1,145 @@
+#ifndef ATOMIC_X86_GCC_INCLUDED
+#define ATOMIC_X86_GCC_INCLUDED
+
+/* Copyright (C) 2006 MySQL AB
+
+   This program is free software; you can redistribute it and/or modify
+   it under the terms of the GNU General Public License as published by
+   the Free Software Foundation; version 2 of the License.
+
+   This program is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+   GNU General Public License for more details.
+
+   You should have received a copy of the GNU General Public License
+   along with this program; if not, write to the Free Software
+   Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA */
+
+/*
+  XXX 64-bit atomic operations can be implemented using
+  cmpxchg8b, if necessary. Though I've heard that not all 64-bit
+  architectures support double-word (128-bit) cas.
+*/
+
+/*
+  No special support of 8 and 16 bit operations are implemented here
+  currently.
+*/
+#undef MY_ATOMIC_HAS_8_AND_16
+
+#ifdef __x86_64__
+#  ifdef MY_ATOMIC_NO_XADD
+#    define MY_ATOMIC_MODE "gcc-amd64" LOCK_prefix "-no-xadd"
+#  else
+#    define MY_ATOMIC_MODE "gcc-amd64" LOCK_prefix
+#  endif
+#else
+#  ifdef MY_ATOMIC_NO_XADD
+#    define MY_ATOMIC_MODE "gcc-x86" LOCK_prefix "-no-xadd"
+#  else
+#    define MY_ATOMIC_MODE "gcc-x86" LOCK_prefix
+#  endif
+#endif
+
+/* fix -ansi errors while maintaining readability */
+#ifndef asm
+#define asm __asm__
+#endif
+
+#ifndef MY_ATOMIC_NO_XADD
+#define make_atomic_add_body(S)         make_atomic_add_body ## S
+#define make_atomic_cas_body(S)         make_atomic_cas_body ## S
+#endif
+
+#define make_atomic_add_body32                                  \
+  asm volatile (LOCK_prefix "; xadd %0, %1;"                    \
+                : "+r" (v), "=m" (*a)                           \
+                : "m" (*a)                                      \
+                : "memory")
+
+#define make_atomic_cas_body32                                  \
+  __typeof__(*cmp) sav;                                         \
+  asm volatile (LOCK_prefix "; cmpxchg %3, %0; setz %2;"	\
+                : "=m" (*a), "=a" (sav), "=q" (ret)             \
+                : "r" (set), "m" (*a), "a" (*cmp)               \
+                : "memory");                                    \
+  if (!ret)                                                     \
+    *cmp= sav
+
+#ifdef __x86_64__
+#define make_atomic_add_body64 make_atomic_add_body32
+#define make_atomic_cas_body64 make_atomic_cas_body32
+
+#define make_atomic_fas_body(S)                                 \
+  asm volatile ("xchg %0, %1;"                                  \
+                : "+r" (v), "=m" (*a)                           \
+                : "m" (*a)                                      \
+                : "memory")
+
+/*
+  Actually 32/64-bit reads/writes are always atomic on x86_64,
+  nonetheless issue memory barriers as appropriate.
+*/
+#define make_atomic_load_body(S)                                \
+  /* Serialize prior load and store operations. */              \
+  asm volatile ("mfence" ::: "memory");                         \
+  ret= *a;                                                      \
+  /* Prevent compiler from reordering instructions. */          \
+  asm volatile ("" ::: "memory")
+#define make_atomic_store_body(S)                               \
+  asm volatile ("; xchg %0, %1;"                                \
+                : "=m" (*a), "+r" (v)                           \
+                : "m" (*a)                                      \
+                : "memory")
+
+#else
+/*
+  Use default implementations of 64-bit operations since we solved
+  the 64-bit problem on 32-bit platforms for CAS, no need to solve it
+  once more for ADD, LOAD, STORE and FAS as well.
+  Since we already added add32 support, we need to define add64
+  here, but we haven't defined fas, load and store at all, so
+  we can fallback on default implementations.
+*/
+#define make_atomic_add_body64                                  \
+  int64 tmp=*a;                                                 \
+  while (!my_atomic_cas64(a, &tmp, tmp+v)) ;                    \
+  v=tmp;
+
+/*
+  On some platforms (e.g. Mac OS X and Solaris) the ebx register
+  is held as a pointer to the global offset table. Thus we're not
+  allowed to use the b-register on those platforms when compiling
+  PIC code, to avoid this we push ebx and pop ebx. The new value
+  is copied directly from memory to avoid problems with a implicit
+  manipulation of the stack pointer by the push.
+
+  cmpxchg8b works on both 32-bit platforms and 64-bit platforms but
+  the code here is only used on 32-bit platforms, on 64-bit
+  platforms the much simpler make_atomic_cas_body32 will work
+  fine.
+*/
+#define make_atomic_cas_body64                                    \
+  asm volatile ("push %%ebx;"                                     \
+                "movl (%%ecx), %%ebx;"                            \
+                "movl 4(%%ecx), %%ecx;"                           \
+                LOCK_prefix "; cmpxchg8b %0;"                     \
+                "setz %2; pop %%ebx"                              \
+                : "=m" (*a), "+A" (*cmp), "=c" (ret)              \
+                : "c" (&set), "m" (*a)                            \
+                : "memory", "esp")
+#endif
+
+/*
+  The implementation of make_atomic_cas_body32 is adaptable to
+  the OS word size, so on 64-bit platforms it will automatically
+  adapt to 64-bits and so it will work also on 64-bit platforms
+*/
+#define make_atomic_cas_bodyptr make_atomic_cas_body32
+
+#ifdef MY_ATOMIC_MODE_DUMMY
+#define make_atomic_load_body(S)   ret=*a
+#define make_atomic_store_body(S)  *a=v
+#endif
+#endif /* ATOMIC_X86_GCC_INCLUDED */
diff -ruN /dev/null b/mysys/my_atomic.c
--- /dev/null	1970-01-01 00:00:00.000000000 +0000
+++ b/mysys/my_atomic.c	2011-06-07 08:59:00.000000000 +0300
@@ -0,0 +1,289 @@
+#ifndef MY_ATOMIC_INCLUDED
+#define MY_ATOMIC_INCLUDED
+
+/* Copyright (C) 2006 MySQL AB
+
+   This program is free software; you can redistribute it and/or modify
+   it under the terms of the GNU General Public License as published by
+   the Free Software Foundation; version 2 of the License.
+
+   This program is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+   GNU General Public License for more details.
+
+   You should have received a copy of the GNU General Public License
+   along with this program; if not, write to the Free Software
+   Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA */
+
+/*
+  This header defines five atomic operations:
+
+  my_atomic_add#(&var, what)
+    'Fetch and Add'
+    add 'what' to *var, and return the old value of *var
+
+  my_atomic_fas#(&var, what)
+    'Fetch And Store'
+    store 'what' in *var, and return the old value of *var
+
+  my_atomic_cas#(&var, &old, new)
+    An odd variation of 'Compare And Set/Swap'
+    if *var is equal to *old, then store 'new' in *var, and return TRUE
+    otherwise store *var in *old, and return FALSE
+    Usually, &old should not be accessed if the operation is successful.
+
+  my_atomic_load#(&var)
+    return *var
+
+  my_atomic_store#(&var, what)
+    store 'what' in *var
+
+  '#' is substituted by a size suffix - 8, 16, 32, 64, or ptr
+  (e.g. my_atomic_add8, my_atomic_fas32, my_atomic_casptr).
+
+  NOTE This operations are not always atomic, so they always must be
+  enclosed in my_atomic_rwlock_rdlock(lock)/my_atomic_rwlock_rdunlock(lock)
+  or my_atomic_rwlock_wrlock(lock)/my_atomic_rwlock_wrunlock(lock).
+  Hint: if a code block makes intensive use of atomic ops, it make sense
+  to take/release rwlock once for the whole block, not for every statement.
+
+  On architectures where these operations are really atomic, rwlocks will
+  be optimized away.
+  8- and 16-bit atomics aren't implemented for windows (see generic-msvc.h),
+  but can be added, if necessary. 
+*/
+
+#include "my_global.h"
+
+#ifndef my_atomic_rwlock_init
+
+#define intptr         void *
+/**
+  Currently we don't support 8-bit and 16-bit operations.
+  It can be added later if needed.
+*/
+#undef MY_ATOMIC_HAS_8_16
+
+#ifndef MY_ATOMIC_MODE_RWLOCKS
+/*
+ * Attempt to do atomic ops without locks
+ */
+#include "atomic/nolock.h"
+#endif
+
+#ifndef make_atomic_cas_body
+/* nolock.h was not able to generate even a CAS function, fall back */
+#include "atomic/rwlock.h"
+#endif
+
+/* define missing functions by using the already generated ones */
+#ifndef make_atomic_add_body
+#define make_atomic_add_body(S)                                 \
+  int ## S tmp=*a;                                              \
+  while (!my_atomic_cas ## S(a, &tmp, tmp+v)) ;                 \
+  v=tmp;
+#endif
+#ifndef make_atomic_fas_body
+#define make_atomic_fas_body(S)                                 \
+  int ## S tmp=*a;                                              \
+  while (!my_atomic_cas ## S(a, &tmp, v)) ;                     \
+  v=tmp;
+#endif
+#ifndef make_atomic_load_body
+#define make_atomic_load_body(S)                                \
+  ret= 0; /* avoid compiler warning */                          \
+  (void)(my_atomic_cas ## S(a, &ret, ret));
+#endif
+#ifndef make_atomic_store_body
+#define make_atomic_store_body(S)                               \
+  (void)(my_atomic_fas ## S (a, v));
+#endif
+
+/*
+  transparent_union doesn't work in g++
+  Bug ?
+
+  Darwin's gcc doesn't want to put pointers in a transparent_union
+  when built with -arch ppc64. Complains:
+  warning: 'transparent_union' attribute ignored
+*/
+#if defined(__GNUC__) && !defined(__cplusplus) && \
+      ! (defined(__APPLE__) && (defined(_ARCH_PPC64) ||defined (_ARCH_PPC)))
+/*
+  we want to be able to use my_atomic_xxx functions with
+  both signed and unsigned integers. But gcc will issue a warning
+  "passing arg N of `my_atomic_XXX' as [un]signed due to prototype"
+  if the signedness of the argument doesn't match the prototype, or
+  "pointer targets in passing argument N of my_atomic_XXX differ in signedness"
+  if int* is used where uint* is expected (or vice versa).
+  Let's shut these warnings up
+*/
+#define make_transparent_unions(S)                              \
+        typedef union {                                         \
+          int  ## S  i;                                         \
+          uint ## S  u;                                         \
+        } U_ ## S   __attribute__ ((transparent_union));        \
+        typedef union {                                         \
+          int  ## S volatile *i;                                \
+          uint ## S volatile *u;                                \
+        } Uv_ ## S   __attribute__ ((transparent_union));
+#define uintptr intptr
+make_transparent_unions(8)
+make_transparent_unions(16)
+make_transparent_unions(32)
+make_transparent_unions(64)
+make_transparent_unions(ptr)
+#undef uintptr
+#undef make_transparent_unions
+#define a       U_a.i
+#define cmp     U_cmp.i
+#define v       U_v.i
+#define set     U_set.i
+#else
+#define U_8    int8
+#define U_16   int16
+#define U_32   int32
+#define U_64   int64
+#define U_ptr  intptr
+#define Uv_8   int8
+#define Uv_16  int16
+#define Uv_32  int32
+#define Uv_64  int64
+#define Uv_ptr intptr
+#define U_a    volatile *a
+#define U_cmp  *cmp
+#define U_v    v
+#define U_set  set
+#endif /* __GCC__ transparent_union magic */
+
+#define make_atomic_cas(S)                                      \
+static inline int my_atomic_cas ## S(Uv_ ## S U_a,              \
+                            Uv_ ## S U_cmp, U_ ## S U_set)      \
+{                                                               \
+  int8 ret;                                                     \
+  make_atomic_cas_body(S);                                      \
+  return ret;                                                   \
+}
+
+#define make_atomic_add(S)                                      \
+static inline int ## S my_atomic_add ## S(                      \
+                        Uv_ ## S U_a, U_ ## S U_v)              \
+{                                                               \
+  make_atomic_add_body(S);                                      \
+  return v;                                                     \
+}
+
+#define make_atomic_fas(S)                                      \
+static inline int ## S my_atomic_fas ## S(                      \
+                         Uv_ ## S U_a, U_ ## S U_v)             \
+{                                                               \
+  make_atomic_fas_body(S);                                      \
+  return v;                                                     \
+}
+
+#define make_atomic_load(S)                                     \
+static inline int ## S my_atomic_load ## S(Uv_ ## S U_a)        \
+{                                                               \
+  int ## S ret;                                                 \
+  make_atomic_load_body(S);                                     \
+  return ret;                                                   \
+}
+
+#define make_atomic_store(S)                                    \
+static inline void my_atomic_store ## S(                        \
+                     Uv_ ## S U_a, U_ ## S U_v)                 \
+{                                                               \
+  make_atomic_store_body(S);                                    \
+}
+
+#ifdef MY_ATOMIC_HAS_8_16
+make_atomic_cas(8)
+make_atomic_cas(16)
+#endif
+make_atomic_cas(32)
+make_atomic_cas(64)
+make_atomic_cas(ptr)
+
+#ifdef MY_ATOMIC_HAS_8_16
+make_atomic_add(8)
+make_atomic_add(16)
+#endif
+make_atomic_add(32)
+make_atomic_add(64)
+
+#ifdef MY_ATOMIC_HAS_8_16
+make_atomic_load(8)
+make_atomic_load(16)
+#endif
+make_atomic_load(32)
+make_atomic_load(64)
+make_atomic_load(ptr)
+
+#ifdef MY_ATOMIC_HAS_8_16
+make_atomic_fas(8)
+make_atomic_fas(16)
+#endif
+make_atomic_fas(32)
+make_atomic_fas(64)
+make_atomic_fas(ptr)
+
+#ifdef MY_ATOMIC_HAS_8_16
+make_atomic_store(8)
+make_atomic_store(16)
+#endif
+make_atomic_store(32)
+make_atomic_store(64)
+make_atomic_store(ptr)
+
+#ifdef _atomic_h_cleanup_
+#include _atomic_h_cleanup_
+#undef _atomic_h_cleanup_
+#endif
+
+#undef U_8
+#undef U_16
+#undef U_32
+#undef U_64
+#undef U_ptr
+#undef Uv_8
+#undef Uv_16
+#undef Uv_32
+#undef Uv_64
+#undef Uv_ptr
+#undef a
+#undef cmp
+#undef v
+#undef set
+#undef U_a
+#undef U_cmp
+#undef U_v
+#undef U_set
+#undef make_atomic_add
+#undef make_atomic_cas
+#undef make_atomic_load
+#undef make_atomic_store
+#undef make_atomic_fas
+#undef make_atomic_add_body
+#undef make_atomic_cas_body
+#undef make_atomic_load_body
+#undef make_atomic_store_body
+#undef make_atomic_fas_body
+#undef intptr
+
+/*
+  the macro below defines (as an expression) the code that
+  will be run in spin-loops. Intel manuals recummend to have PAUSE there.
+  It is expected to be defined in include/atomic/ *.h files
+*/
+#ifndef LF_BACKOFF
+#define LF_BACKOFF (1)
+#endif
+
+#define MY_ATOMIC_OK       0
+#define MY_ATOMIC_NOT_1CPU 1
+extern int my_atomic_initialize();
+
+#endif
+
+#endif /* MY_ATOMIC_INCLUDED */
